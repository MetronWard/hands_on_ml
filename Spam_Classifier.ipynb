{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMumdfI85x+DvFD9y6U5kCl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MetronWard/hands_on_ml/blob/main/Spam_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading Data"
      ],
      "metadata": {
        "id": "KGmPZubYmQEu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "id": "415BRvX5mCOy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tarfile\n",
        "import urllib.request\n",
        "\n",
        "DOWNLOAD_ROOT = \"http://spamassassin.apache.org/old/publiccorpus/\"\n",
        "HAM_URL = DOWNLOAD_ROOT + \"20021010_hard_ham.tar.bz2\"\n",
        "SPAM_URL = DOWNLOAD_ROOT + \"20030228_spam.tar.bz2\"\n",
        "SPAM_PATH = os.path.join(\"datasets\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_spam_dataset(ham_url:str=HAM_URL, spam_url:str=SPAM_URL, spam_path=SPAM_PATH):\n",
        "    if not os.path.isdir(spam_path):\n",
        "        os.makedirs(spam_path)\n",
        "    for file_name, url in ((\"ham.ter.bz2\", ham_url), (\"spam.tar.bz2\", spam_url)):\n",
        "        path = os.path.join(spam_path, file_name)\n",
        "        if not os.path.isfile(path):\n",
        "            urllib.request.urlretrieve(url, path)\n",
        "        tar_bz2_file = tarfile.open(path)\n",
        "        tar_bz2_file.extractall(path=spam_path)\n",
        "        tar_bz2_file.close()"
      ],
      "metadata": {
        "id": "cj2qCRNLmv70"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fetch_spam_dataset()"
      ],
      "metadata": {
        "id": "bOsTsrswm2Fh"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Obtaining the email data"
      ],
      "metadata": {
        "id": "tlVfmMz9M5vU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HAM_DIR = os.path.join(SPAM_PATH, \"hard_ham\")\n",
        "SPAM_DIR = os.path.join(SPAM_PATH, \"spam\")\n",
        "\n",
        "os.remove(os.path.join(SPAM_DIR, \"cmds\"))\n",
        "\n",
        "ham_filenames = [file_name for file_name in os.listdir(HAM_DIR)]\n",
        "spam_filenames = [file_name for file_name in os.listdir(SPAM_DIR)]"
      ],
      "metadata": {
        "id": "1OY52abANIYk"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for item in zip([\"Ham emails\", \"Spam emails\"], [len(ham_filenames), len(spam_filenames)]):\n",
        "  print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRZFiT3MM8Zw",
        "outputId": "82abc560-5061-4a67-e186-dd629a0c196a"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Ham emails', 250)\n",
            "('Spam emails', 500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import email\n",
        "import email.policy as policy\n",
        "\n",
        "def load_email(is_spam:bool, file_name:str, path:str):\n",
        "  dir = \"spam\" if is_spam else \"hard_ham\"\n",
        "  with open(os.path.join(path, dir, file_name), \"rb\") as file:\n",
        "    return email.parser.BytesParser(policy=policy.default).parse(file)"
      ],
      "metadata": {
        "id": "y_4-fqv6OssS"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ham_files = [load_email(is_spam=False, file_name=file_name, path=SPAM_PATH) for file_name in ham_filenames]\n",
        "spam_files = [load_email(is_spam=True, file_name=file_name, path=SPAM_PATH) for file_name in spam_filenames]"
      ],
      "metadata": {
        "id": "PwrQZNxMP93N"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting into train and test set"
      ],
      "metadata": {
        "id": "xYC38DxpSFYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "x = np.array(ham_files + spam_files, dtype=object)\n",
        "y = np.array([1] * len(ham_files) + [0] * len(spam_files))\n",
        "\n",
        "x_train_full, x_test, y_train_full, y_test  = train_test_split(x,y, random_state=42, test_size=0.2)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train_full, y_train_full, random_state=42, test_size=0.2)"
      ],
      "metadata": {
        "id": "xpWVYLE8SEGW"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8n6FHQfnTXjO",
        "outputId": "7be881ee-c936-4d1c-daa4-1eab00555fe5"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(480,)"
            ]
          },
          "metadata": {},
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Rplw_STTg6G",
        "outputId": "c73e93fe-8002-4bdf-e9f4-3153e95f0cff"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150,)"
            ]
          },
          "metadata": {},
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def html_to_text(email):\n",
        "  soup = BeautifulSoup(email)\n",
        "  links = soup.find_all(\"a\")\n",
        "  for link in links:\n",
        "    text = soup.new_tag(\"p\")\n",
        "    text.string = \"HYPERLINK\"\n",
        "    link.replace_with(text)\n",
        "  return soup.text"
      ],
      "metadata": {
        "id": "4f55fNF6Ts8p"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def email_to_text(email):\n",
        "  html = None\n",
        "  for part in email.walk():\n",
        "    c_type = part.get_content_type()\n",
        "    if not c_type in (\"text/plain\", \"text/html\"):\n",
        "      continue\n",
        "    try:\n",
        "      content = part.get_content()\n",
        "    except:\n",
        "      content = str(part.get_payload())\n",
        "    if c_type == \"text/plain\":\n",
        "      return content\n",
        "    else:\n",
        "      html = content\n",
        "  if html:\n",
        "    return html_to_text(html)"
      ],
      "metadata": {
        "id": "Rsg4M6X0VDG5"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(email_to_text(x_train[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00E87CMDUfNs",
        "outputId": "133d4b26-334c-4302-a8aa-eda7d202776d"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "THANK YOU FOR SHOPPING WITH US\n",
            "\n",
            "\n",
            "GIFTS FOR ALL OCCASIONS\n",
            " \n",
            "FREE GIFT WITH $50.00 PURCHASE\n",
            "\n",
            "For a limited time only, receive this 11 plush Santa Bear, FREE, with your purchase of $50.00 or more. \n",
            "When your order totals $50.00 or more (order must be $50.00 or more before shipping and handling) this Santa Bear is added to your cart for free, while supplies last.\n",
            "\n",
            "\n",
            "\n",
            "Mary's Store would like to thank you for being a valued customer.   As our way of saying thanks to you, the customer, we are offering a 15% discount  on all purchases made during the month of  November.  Just enter the word:\n",
            "THANKS   \n",
            "In the discount code box during checkout to receive your automatic 15% discount.\n",
            "HYPERLINK HYPERLINK\n",
            "HYPERLINK\n",
            "If you do not wish to receive further discounts please HYPERLINK and type remove in the subject line.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKdbGgksWBJ5",
        "outputId": "ca251b5a-cf0b-4b0b-ef97-59e521de9645"
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining Pipeline"
      ],
      "metadata": {
        "id": "or1F8wtoWmfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install urlextract nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OD8GJl2WlbH",
        "outputId": "6f4c65cf-bf37-445f-a224-9b4afb441b17"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: urlextract in /usr/local/lib/python3.10/dist-packages (1.8.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from urlextract) (3.4)\n",
            "Requirement already satisfied: uritools in /usr/local/lib/python3.10/dist-packages (from urlextract) (4.0.2)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from urlextract) (3.11.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from urlextract) (3.12.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import urlextract\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "stemmer = nltk.PorterStemmer()\n",
        "url_extractor = urlextract.URLExtract()"
      ],
      "metadata": {
        "id": "iqSKhvceZcsU"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import TransformerMixin, BaseEstimator\n",
        "\n",
        "class EmailToWordCounter(TransformerMixin, BaseEstimator):\n",
        "  def __init__(self,\n",
        "               lower_case=True,\n",
        "               replace_numbers=True,\n",
        "               replace_urls=True,\n",
        "               remove_punctuations=True,\n",
        "               stemming=True) -> None:\n",
        "    super().__init__()\n",
        "    self.lower_case = lower_case\n",
        "    self.replace_numbers = replace_numbers\n",
        "    self.replace_urls = replace_urls\n",
        "    self.stemming = stemming\n",
        "    self.remove_punctuations = remove_punctuations\n",
        "\n",
        "  def fit(self, x, y=None):\n",
        "    return self\n",
        "\n",
        "  def transform(self, x, y=None):\n",
        "    x_transformed = []\n",
        "    for email in x:\n",
        "      text = email_to_text(email) or \"\"\n",
        "      if self.lower_case:\n",
        "        text = text.lower()\n",
        "      if self.replace_urls:\n",
        "        urls = list(set(url_extractor.find_urls(text)))\n",
        "        urls.sort(key=lambda url: len(url), reverse=True)\n",
        "        for url in urls:\n",
        "          text.replace(url, \"URL\")\n",
        "      if self.replace_numbers:\n",
        "        text = re.sub(r'\\d+(?:\\.\\d*)?(?:[eE][+-]?\\d+)?', 'NUMBER', text)\n",
        "      if self.replace_numbers:\n",
        "        text = re.sub(r\"\\W+\", \" \", text, flags=re.M)\n",
        "      word_counts = Counter(text.split())\n",
        "      if self.stemming :\n",
        "        stemmed_word_count = Counter()\n",
        "        for word, count in word_counts.items():\n",
        "          stemmed_word = stemmer.stem(word)\n",
        "          stemmed_word_count[stemmed_word] += count\n",
        "        word_counts = stemmed_word_count\n",
        "        # complete.append(word_counts)\n",
        "      x_transformed.append(word_counts)\n",
        "    return np.array(x_transformed)"
      ],
      "metadata": {
        "id": "hcpbg72xW6tz"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_few = x_train[:3]\n",
        "X_few_wordcounts = EmailToWordCounter().fit_transform(X_few)"
      ],
      "metadata": {
        "id": "GqwDVAmhdRRc"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_few_wordcounts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hx-7nsIAeFo2",
        "outputId": "bbf373ad-6827-4de7-a615-6329cb06f768"
      },
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([Counter({'number': 7, 'for': 5, 'to': 5, 'the': 5, 'thank': 4, 'you': 4, 'your': 4, 'discount': 4, 'hyperlink': 4, 'with': 3, 'free': 3, 'purchas': 3, 'a': 3, 'receiv': 3, 'of': 3, 'or': 3, 'more': 3, 'gift': 2, 'all': 2, 'thi': 2, 'santa': 2, 'bear': 2, 'order': 2, 'be': 2, 'and': 2, 'custom': 2, 'dure': 2, 'in': 2, 'shop': 1, 'us': 1, 'occas': 1, 'limit': 1, 'time': 1, 'onli': 1, 'plush': 1, 'when': 1, 'total': 1, 'must': 1, 'befor': 1, 'ship': 1, 'handl': 1, 'is': 1, 'ad': 1, 'cart': 1, 'while': 1, 'suppli': 1, 'last': 1, 'mari': 1, 's': 1, 'store': 1, 'would': 1, 'like': 1, 'valu': 1, 'as': 1, 'our': 1, 'way': 1, 'say': 1, 'we': 1, 'are': 1, 'offer': 1, 'on': 1, 'made': 1, 'month': 1, 'novemb': 1, 'just': 1, 'enter': 1, 'word': 1, 'code': 1, 'box': 1, 'checkout': 1, 'automat': 1, 'if': 1, 'do': 1, 'not': 1, 'wish': 1, 'further': 1, 'pleas': 1, 'type': 1, 'remov': 1, 'subject': 1, 'line': 1}),\n",
              "       Counter({'the': 32, 'to': 23, 'of': 22, 'and': 15, 'in': 12, 'you': 11, 'thi': 10, 'number': 8, 'i': 7, 'we': 7, 'for': 6, 'a': 6, 'transfer': 6, 'that': 6, 'have': 6, 'your': 6, 'contract': 5, 'by': 5, 'transact': 5, 'is': 5, 'be': 5, 'will': 5, 'as': 5, 'my': 4, 'account': 4, 'are': 4, 'our': 4, 'new': 3, 'which': 3, 'sum': 3, 'state': 3, 'been': 3, 'civil': 3, 'servic': 3, 'name': 3, 'am': 2, 'dr': 2, 'jame': 2, 'alabi': 2, 'award': 2, 'review': 2, 'set': 2, 'govern': 2, 'nigeria': 2, 'confidenti': 2, 'foreign': 2, 'were': 2, 'execut': 2, 'favor': 2, 'n': 2, 'these': 2, 'over': 2, 'us': 2, 'twenti': 2, 'amount': 2, 'now': 2, 'approv': 2, 'compani': 2, 'offici': 2, 'from': 2, 'or': 2, 'on': 2, 'at': 2, 'cours': 2, 'work': 2, 'fund': 2, 'assur': 2, 'risk': 2, 'free': 2, 'legal': 2, 'it': 2, 'deserv': 2, 'with': 2, 'want': 2, 'year': 2, 'should': 2, 'take': 2, 'full': 2, 'dear': 1, 'sir': 1, 'chairman': 1, 'committe': 1, 'up': 1, 'feder': 1, 'under': 1, 'civilian': 1, 'dispens': 1, 'exist': 1, 'one': 1, 'came': 1, 'know': 1, 'search': 1, 'reliabl': 1, 'reput': 1, 'person': 1, 'handl': 1, 'veri': 1, 'involv': 1, 'huge': 1, 'money': 1, 'there': 1, 'seri': 1, 'consortium': 1, 'multi': 1, 'nation': 1, 'oil': 1, 'industri': 1, 'p': 1, 'c': 1, 'origin': 1, 'valu': 1, 'deliber': 1, 'invoic': 1, 'twelv': 1, 'million': 1, 'three': 1, 'hundr': 1, 'thousand': 1, 'unit': 1, 'dollar': 1, 'ha': 1, 'readi': 1, 'actual': 1, 'fulli': 1, 'paid': 1, 'project': 1, 'commiss': 1, 'consequ': 1, 'colleagu': 1, 'total': 1, 'subsequ': 1, 'disburs': 1, 'sinc': 1, 'servant': 1, 'prohibit': 1, 'code': 1, 'conduct': 1, 'bureau': 1, 'law': 1, 'oper': 1, 'open': 1, 'needless': 1, 'say': 1, 'trust': 1, 'repos': 1, 'junctur': 1, 'enorm': 1, 'return': 1, 'agre': 1, 'offer': 1, 'while': 1, 'shall': 1, 'asid': 1, 'incident': 1, 'expens': 1, 'intern': 1, 'extern': 1, 'between': 1, 'both': 1, 'parti': 1, 'mandat': 1, 'remit': 1, 'balanc': 1, 'other': 1, 'due': 1, 'modal': 1, 'out': 1, 'highest': 1, 'level': 1, 'ministri': 1, 'financ': 1, 'central': 1, 'bank': 1, 'immedi': 1, 'within': 1, 'day': 1, 'subject': 1, 'satisfact': 1, 'abov': 1, 'term': 1, 'role': 1, 'accord': 1, 'mutual': 1, 'secur': 1, 'whole': 1, 'procedur': 1, 'process': 1, 'ani': 1, 'may': 1, 'nomin': 1, 'bonefid': 1, 'beneficiari': 1, 'onc': 1, 'more': 1, 'understand': 1, 'put': 1, 'five': 1, 'countri': 1, 'avers': 1, 'imag': 1, 'career': 1, 'dent': 1, 'matter': 1, 'therefor': 1, 'treat': 1, 'utmost': 1, 'secreci': 1, 'urgenc': 1, 'pleas': 1, 'signifi': 1, 'intent': 1, 'assist': 1, 'send': 1, 'me': 1, 'repli': 1, 'email': 1, 'posit': 1, 'if': 1, 'further': 1, 'step': 1, 'brief': 1, 'detail': 1, 'viabl': 1, 'busi': 1, 'propos': 1, 'done': 1, 'homework': 1, 'properli': 1, 'quit': 1, 'believ': 1, 'protect': 1, 'interest': 1, 'deal': 1, 'strictli': 1, 'still': 1, 'intend': 1, 'retir': 1, 'honor': 1, 'kindli': 1, 'expedit': 1, 'action': 1, 'behind': 1, 'schedul': 1, 'enabl': 1, 'includ': 1, 'next': 1, 'batch': 1, 'would': 1, 'constitut': 1, 'quarter': 1, 'payment': 1, 'financi': 1, 'thank': 1, 'god': 1, 'bless': 1}),\n",
              "       Counter({'the': 17, 'of': 14, 'to': 13, 'thi': 9, 'for': 9, 'number': 9, 'you': 8, 'as': 8, 'your': 7, 'and': 7, 'will': 7, 'me': 6, 'be': 6, 'i': 5, 'in': 5, 'consign': 5, 'a': 4, 'wa': 4, 'secur': 4, 'money': 4, 'william': 3, 'falana': 3, 'busi': 3, 'my': 3, 'us': 3, 'compani': 3, 'by': 3, 'use': 3, 'with': 3, 'requir': 3, 'transact': 3, 'send': 3, 'nigeria': 2, 'san': 2, 'barrist': 2, 'reach': 2, 'through': 2, 'confid': 2, 'both': 2, 'state': 2, 'lodg': 2, 'box': 2, 'such': 2, 'doe': 2, 'not': 2, 'know': 2, 'hi': 2, 'he': 2, 'conclud': 2, 'an': 2, 'offshor': 2, 'beneficiari': 2, 'that': 2, 'or': 2, 'are': 2, 'e': 2, 'mail': 2, 'name': 2, 'which': 2, 'also': 2, 'telephon': 2, 'de': 2, 'mobil': 2, 'senior': 1, 'advoc': 1, 'barr': 1, 'dear': 1, 'sir': 1, 'am': 1, 'member': 1, 'bar': 1, 'associ': 1, 'nba': 1, 'contact': 1, 'world': 1, 'encyclopaedia': 1, 'henc': 1, 'made': 1, 'up': 1, 'mind': 1, 'introduc': 1, 'mutual': 1, 'benefit': 1, 'sum': 1, 'usdnumberm': 1, 'forti': 1, 'eight': 1, 'million': 1, 'unit': 1, 'into': 1, 'here': 1, 'countri': 1, 'late': 1, 'head': 1, 'gen': 1, 'sani': 1, 'abacha': 1, 'safe': 1, 'keep': 1, 'vault': 1, 'label': 1, 'person': 1, 'belong': 1, 'true': 1, 'content': 1, 'origin': 1, 'meant': 1, 'polit': 1, 'campaign': 1, 'becaus': 1, 'famili': 1, 'attorney': 1, 'relev': 1, 'document': 1, 'paper': 1, 'relat': 1, 'deposit': 1, 'befor': 1, 'die': 1, 'cardiac': 1, 'arrest': 1, 'matter': 1, 'fact': 1, 'we': 1, 'have': 1, 'all': 1, 'arrang': 1, 'move': 1, 'diplomat': 1, 'mean': 1, 'their': 1, 'affili': 1, 'offic': 1, 'where': 1, 'put': 1, 'claim': 1, 'bonafid': 1, 'should': 1, 'is': 1, 'safeti': 1, 'risk': 1, 'free': 1, 'it': 1, 'involv': 1, 'drug': 1, 'terrorist': 1, 'fund': 1, 'if': 1, 'interest': 1, 'carri': 1, 'out': 1, 'assist': 1, 'gener': 1, 'expens': 1, 'immedi': 1, 'full': 1, 'address': 1, 'draft': 1, 'agreement': 1, 'guid': 1, 'protect': 1, 'effect': 1, 'chang': 1, 'ownership': 1, 'fax': 1, 'easi': 1, 'commun': 1, 'onc': 1, 'notifi': 1, 'willing': 1, 'abov': 1, 'within': 1, 'seven': 1, 'work': 1, 'day': 1, 'wait': 1, 'urgent': 1, 'repli': 1, 'can': 1, 'on': 1, 'cell': 1, 'no': 1, 'altern': 1, 'williamsfalana': 1, 'caramail': 1, 'com': 1, 'best': 1, 'regard': 1, '_________________________________________________________': 1, 'envoyez': 1, 'messag': 1, 'musicaux': 1, 'sur': 1, 'le': 1, 'portabl': 1, 'vo': 1, 'ami': 1, 'http': 1, 'lyco': 1, 'fr': 1, 'local': 1, 'sms_musicaux': 1})],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "class WordCounterVector(BaseEstimator, TransformerMixin):\n",
        "\n",
        "  def __init__(self, vocabulary_size):\n",
        "    self.vocabulary_size = vocabulary_size\n",
        "\n",
        "  def fit(self, x, y=None):\n",
        "    total_count = Counter()\n",
        "    for word_count in x:\n",
        "      for word, count in word_count.items():\n",
        "        total_count[word] += min(count, 10)\n",
        "    most_common = total_count.most_common()[:self.vocabulary_size]\n",
        "    self.vocabulary_ = {word:index+1 for index, (word, count) in enumerate(most_common)}\n",
        "    return self\n",
        "\n",
        "  def transform(self, x, y=None):\n",
        "    rows = []\n",
        "    cols = []\n",
        "    data = []\n",
        "    for row, word_counts in enumerate(x):\n",
        "      for word, count in word_counts.items():\n",
        "        rows.append(row)\n",
        "        cols.append(self.vocabulary_.get(word, 0))\n",
        "        data.append(count)\n",
        "    return csr_matrix((data, (rows, cols)), shape=(len(x), self.vocabulary_size + 1))"
      ],
      "metadata": {
        "id": "X8Z8WPl_f1Hv"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_transformer = WordCounterVector(vocabulary_size=10)\n",
        "X_few_vectors = vocab_transformer.fit_transform(X_few_wordcounts)\n",
        "X_few_vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-dIl3O2iIDk",
        "outputId": "d3c6f8ca-804b-4e3d-8d7c-9373f242f452"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<3x11 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 33 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_few_vectors.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHb55pG4iKQH",
        "outputId": "632c8e04-5336-4f45-c191-04562259f1d7"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[102,   5,   5,   7,   3,   4,   2,   5,   2,   4,   2],\n",
              "       [376,  23,  32,   8,  22,  11,  10,   6,  15,   6,  12],\n",
              "       [290,  13,  17,   9,  14,   8,   9,   9,   7,   7,   5]])"
            ]
          },
          "metadata": {},
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "processin_pipeline = Pipeline([\n",
        "    (\"email_to_word\", EmailToWordCounter()),\n",
        "    (\"wordcount_to_vector\", WordCounterVector(vocabulary_size=100))\n",
        "])"
      ],
      "metadata": {
        "id": "QjLqAzrcilOL"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_scaled = processin_pipeline.fit_transform(x_train)\n",
        "x_test_scaled = processin_pipeline.transform(x_test)\n",
        "x_valid_scaled = processin_pipeline.transform(x_val)"
      ],
      "metadata": {
        "id": "B8JlN3_1ja2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Model"
      ],
      "metadata": {
        "id": "fQ4m7KUcvVks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "\n",
        "model = Sequential([\n",
        "    Input(shape=x_train_scaled.shape[1:], name=\"Input_Layer\"),\n",
        "    Dense(101, activation=\"relu\", name=\"Dense_1\"),\n",
        "    Dense(50, activation=\"relu\", name=\"Dense_2\"),\n",
        "    Dense(10, activation=\"relu\", name=\"Dense_4\"),\n",
        "    Dense(1, activation=\"sigmoid\", name=\"Output\"),\n",
        "], name=\"Spam_Detector\")"
      ],
      "metadata": {
        "id": "MGP3IVQsov9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "YOt7Tu-MpJMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])\n",
        "history = model.fit(x_train_scaled, y_train, epochs=40, validation_data=(x_valid_scaled,y_val))"
      ],
      "metadata": {
        "id": "Ded-VOF9pw1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_df = pd.DataFrame(history.history)\n",
        "history_df.plot(figsize=(8,5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0,1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "u7HWokXhsa-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test_scaled, y_test)"
      ],
      "metadata": {
        "id": "nhvjuh1dszZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict(x_test_scaled)"
      ],
      "metadata": {
        "id": "RJJ3p-FVvTQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "id": "UI78sK-EvvU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = (preds >= 0.5)"
      ],
      "metadata": {
        "id": "y1AZXjYXvw1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, PrecisionRecallDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = ConfusionMatrixDisplay(\n",
        "    confusion_matrix(\n",
        "        y_true=y_test,\n",
        "        y_pred=preds,\n",
        "        normalize='all'\n",
        "    ),\n",
        "    display_labels=['Spam', 'Ham'],\n",
        ")\n",
        "\n",
        "# Plot the confusion matrix with specified formatting\n",
        "cm.plot(\n",
        "    values_format='.2%',  # Display values as percentages with two decimal places\n",
        "    colorbar=False,  # Do not display the color bar\n",
        ")\n",
        "\n",
        "# Display the confusion matrix plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5DLe54DPviii"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}